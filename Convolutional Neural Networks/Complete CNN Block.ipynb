{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a691b14-78ba-4c15-87f6-f1e5cfaa754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Initialize (two equivalent ways of instantiating our functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf13668-1b9f-4deb-8c00-2a1a2011d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.conv1 = nn.Conv2d(3, 16, 3, padding=1),\n",
    "self.pool = nn.MaxPool2d(2, 2),\n",
    "self.relu1 = nn.ReLU()\n",
    "self.drop1 = nn.Dropout2d(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33287b8e-0296-44fe-bf5b-d669756d11f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.conv_block = nn.Sequential(\n",
    "  nn.Conv2d(3, 16, 3, padding=1),\n",
    "  nn.MaxPool2d(2, 2),\n",
    "  nn.ReLU(),\n",
    "  nn.Dropout2d(0.2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e643916-9071-4d76-b89c-e07e90e565d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "\n",
    "  def __init__(self, n_classes):\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    # Create layers. In this case just a standard MLP\n",
    "    self.model = nn.Sequential(\n",
    "      # First conv + maxpool + relu\n",
    "      nn.Conv2d(3, 16, 3, padding=1),\n",
    "      nn.MaxPool2d(2, 2),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout2d(0.2),\n",
    "\n",
    "      # Second conv + maxpool + relu\n",
    "      nn.Conv2d(16, 32, 3, padding=1),\n",
    "      nn.MaxPool2d(2, 2),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout2d(0.2),\n",
    "\n",
    "      # Third conv + maxpool + relu\n",
    "      nn.Conv2d(32, 64, 3, padding=1),\n",
    "      nn.MaxPool2d(2, 2),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout2d(0.2),\n",
    "\n",
    "      # Flatten feature maps\n",
    "      nn.Flatten(),\n",
    "\n",
    "      # Fully connected layers. This assumes\n",
    "      # that the input image was 32x32\n",
    "      nn.Linear(1024, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(0.5),\n",
    "      nn.Linear(128, n_classes)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    # nn.Sequential will call the layers \n",
    "    # in the order they have been inserted\n",
    "    return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc97f9e-20fe-4dc7-8538-4a4be51a9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # convolutional layer 1. It sees 3x32x32 image tensor\n",
    "        # and produces 16 feature maps 32x32 (i.e., a tensor 16x32x32)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # 2x2 pooling with stride 2. It sees tensors 16x32x32\n",
    "        # and halves their size, i.e., the output will be 16x16x16\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # convolutional layer (sees the output of the prev layer, i.e.,\n",
    "        # 16x16x16 tensor)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)  # -> 32x16x16\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # -> 32x8x8\n",
    "\n",
    "        # convolutional layer\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)  # -> 64x8x8\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)  # -> 64x4x4\n",
    "\n",
    "        # linear layer (64 * 4 * 4 -> 500)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
    "        self.dp1 = nn.Dropout(0.5)\n",
    "        self.rl1 = nn.ReLU()\n",
    "\n",
    "        # linear layer (500 -> 10)\n",
    "        self.fc2 = nn.Linear(500, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.relu1(self.pool1(self.conv1(x)))\n",
    "        x = self.relu2(self.pool2(self.conv2(x)))\n",
    "        x = self.relu3(self.pool3(self.conv3(x)))\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.rl1(self.dp1(self.fc1(x)))\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272eb8bf-83cd-42a1-91f1-da5c7b5161ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a1a4d2-8ea0-4ea2-8f99-4700d7d4c4fd",
   "metadata": {},
   "source": [
    "Number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6bc59-b025-4679-9781-13ce68cfb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bfea20-1443-468c-bdd3-25f69fe13b44",
   "metadata": {},
   "source": [
    "Specify loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56afb4b5-b270-444b-b184-0ef5da2f51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# specify loss function (categorical cross-entropy)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0a41ad-5346-48a8-9109-02bafd796351",
   "metadata": {},
   "source": [
    "Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b68e8e-e586-4161-8876-235bd609df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efdd1b9-0306-417e-926b-e950c2ad1673",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(\n",
    "    data_loaders,\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    20,\n",
    "    \"cifar10_best_valid.pt\",\n",
    "    interactive_tracking=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63f97ac-d31c-48c8-8019-5b36c495158c",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceccfb54-6ac9-4fe7-96c9-fe8e545b4238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import one_epoch_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c3f425-f41b-4065-ad9e-c81155f44073",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, preds, actuals = one_epoch_test(data_loaders['valid'], model, loss)\n",
    "from helpers import plot_confusion_matrix\n",
    "\n",
    "cm = plot_confusion_matrix(preds, actuals, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b88f072-df03-45bf-a193-ac0731e6e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy by class:\\n\")\n",
    "for i, col in enumerate(cm):\n",
    "    print(f\"    {col:11s}: {cm[col][i] / cm[col].sum():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ec4a3-176f-4481-bc52-baa2dc46481a",
   "metadata": {},
   "source": [
    "To visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fad01c-87ab-43d5-97ed-5e4dbe419445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one batch of test images\n",
    "dataiter = iter(data_loaders['test'])\n",
    "\n",
    "for i in range(2):\n",
    "    images, labels = dataiter.next()\n",
    "    images.numpy()\n",
    "\n",
    "    # move model inputs to cuda, if GPU available\n",
    "    if train_on_gpu:\n",
    "        images = images.cuda()\n",
    "\n",
    "    # get sample outputs\n",
    "    output = model(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n",
    "\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig, subs = plt.subplots(2, 10, figsize=(25, 4))\n",
    "    for i, ax in enumerate(subs.flatten()):\n",
    "        imshow(images[i].cpu().numpy(), ax)\n",
    "        ax.set_title(\"{} ({})\".format(classes[preds[i]], classes[labels[i]]),\n",
    "                     color=(\"green\" if preds[i]==labels[i].item() else \"red\"))\n",
    "        ax.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
