{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a230a7-c10c-4f63-8ce8-0751fba48914",
   "metadata": {},
   "source": [
    "Image Augmentation\n",
    "- if you want your network to be insensitive to changes such as rotation, translation, and dilation, you can use the same input image and rotate it, translate it, and scale it and ask the network not to change its prediction\n",
    "\n",
    "Method to\n",
    "- Increase the robustness of the network\n",
    "- Avoid overfitting\n",
    "- Introduce rotational, translational and scale invariance as well as insensitiveness to color changes\n",
    "- Avoid shortcut learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385addfb-d9a7-4036-a215-71942c73afc3",
   "metadata": {},
   "source": [
    "Augmentation Pipeline\n",
    "input image -> resize -> randomeAffine -> ColorJitter -> RandomHorizaontalFlip -> RandomCrop -> ToTensor -> Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71311775-89b5-4c93-992d-99e0626a2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "train_transforms = T.Compose(\n",
    "    [\n",
    "        # The size here depends on your application. Here let's use 256x256\n",
    "        T.Resize(256),\n",
    "        # Let's apply random affine transformations (rotation, translation, shear)\n",
    "        # (don't overdo here!)\n",
    "        T.RandomAffine(scale=(0.9, 1.1), translate=(0.1, 0.1), degrees=10),\n",
    "        # Color modifications. Here I exaggerate to show the effect \n",
    "        T.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "        # Apply an horizontal flip with 50% probability (i.e., if you pass\n",
    "        # 100 images through around half of them will undergo the flipping)\n",
    "        T.RandomHorizontalFlip(0.5),\n",
    "        # Finally take a 224x224 random part of the image\n",
    "        T.RandomCrop(224, padding_mode=\"reflect\", pad_if_needed=True),  # -\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ec85a-6563-441e-bf7b-c0d8e8c33e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "testval_transforms = T.Compose(\n",
    "    [\n",
    "        # The size here depends on your application. Here let's use 256x256\n",
    "        T.Resize(256),\n",
    "        # Let's take the central 224x224 part of the image\n",
    "        T.CenterCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de8c68-0b5c-4e1f-a530-ec27c642acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resize and crop should be the same as applied during training for best performance\n",
    "# The normalization should be the same between training and inference (validation and test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd879d-0c7f-439e-a4a3-a53d9e3a12b8",
   "metadata": {},
   "source": [
    "example of autotransform\n",
    "parametrizes the strength of the augmentations with one single parameter that can be varied to easily find the amount of augmentations that provides the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144eddc8-98b1-46a7-bb74-62b0ab496276",
   "metadata": {},
   "outputs": [],
   "source": [
    "T.RandAugment(num_ops, magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386d9f7-89a9-4480-a9b4-d0190ab0a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_ops: the number of random transformations applied. Defaut: 2\n",
    "# magnitude: the strength of the augmentations. The larger the value, the more diverse and extreme the augmentations will become."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
