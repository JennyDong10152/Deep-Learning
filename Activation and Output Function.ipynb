{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "098b8124-338c-4d91-a3f9-1ba531e5c518",
   "metadata": {},
   "source": [
    "our choice of output function depends on two primary factors about what you are trying to predict: its shape and its range.\n",
    "\n",
    "This means that our output function is determined by what we're trying to do: classification or regression.\n",
    "\n",
    "Common output functions include:\n",
    "\n",
    "Sigmoid for binary classification -> value between 0 and 1\n",
    "Softmax for multi-class classification -> multiclass cross entrophy\n",
    "Identity or ReLU for regression -> mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5e45a-afb0-4758-b57e-a9cca038cf9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed85108f-9f42-4c9b-bfdb-a333f519a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dc0c7e-0b87-4e77-b777-7eff25add086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish our transform\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load train and test datasets\n",
    "training_data = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Create the training and test dataloaders with a batch size of 32\n",
    "train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6e7a53-dc5b-4162-8ad3-16016ccc40e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is provided for you. \n",
    "# Feel free to look it over but if you modify it, it may break!\n",
    "def train_network_classification(net, train_loader, test_loader):\n",
    "    num_epochs = 10\n",
    "    \n",
    "    # We'll use Negative Log Likelihood Loss as our objective function here. Leave it fixed for now.\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # Don't worry about the choice of optimizer here. Leave it fixed for now.\n",
    "    optimizer = optim.SGD(mlp.parameters(), lr=0.005, momentum=0.9)\n",
    "    \n",
    "    # Establish a list for our history\n",
    "    train_loss_history = list()\n",
    "    val_loss_history = list()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            # data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # Pass to GPU if available.\n",
    "            if torch.cuda.is_available():\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            train_loss += loss.item()\n",
    "        print(f'Epoch {epoch + 1} training accuracy: {train_correct/len(train_loader):.2f}% training loss: {train_loss/len(train_loader):.5f}')\n",
    "        train_loss_history.append(train_loss)\n",
    "\n",
    "        \n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        net.eval()\n",
    "        for inputs, labels in test_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_loss += loss.item()\n",
    "        print(f'Epoch {epoch + 1} validation accuracy: {val_correct/len(test_loader):.2f}% validation loss: {val_loss/len(test_loader):.5f}')\n",
    "        val_loss_history.append(val_loss)           \n",
    "\n",
    "    plt.plot(train_loss_history, label=\"Training Loss\")\n",
    "    plt.plot(val_loss_history, label=\"Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def train_network_regression(net, train_loader, test_loader):\n",
    "    num_epochs = 10\n",
    "    \n",
    "    criterion = nn.L1Loss(reduction='sum')\n",
    "\n",
    "    # Don't worry about the choice of optimizer here. Leave it fixed for now.\n",
    "    optimizer = optim.SGD(mlp.parameters(), lr=0.05)\n",
    "    \n",
    "    # Establish a list for our history\n",
    "    train_loss_history = list()\n",
    "    val_loss_history = list()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        train_loss = 0.0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            # data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # Pass to GPU if available.\n",
    "            if torch.cuda.is_available():\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        print(f'Epoch {epoch + 1} training loss: {train_loss/len(train_loader):.5f}')\n",
    "        train_loss_history.append(train_loss)\n",
    "\n",
    "        \n",
    "        val_loss = 0.0\n",
    "        net.eval()\n",
    "        for inputs, labels in test_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "        print(f'Epoch {epoch + 1} validation loss: {val_loss/len(test_loader):.5f}')\n",
    "        val_loss_history.append(val_loss)           \n",
    "\n",
    "    plt.plot(train_loss_history, label=\"Training Loss\")\n",
    "    plt.plot(val_loss_history, label=\"Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084d769-1dc1-42ce-b452-ee1964a402b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = F.relu\n",
    "        self.output = F.log_softmax\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.output(self.fc3(x), dim=1) # For some output functions, may need to specify dimension.\n",
    "        return x\n",
    "\n",
    "# Do not change the name of your model or later cells may fail!\n",
    "mlp = CIFAR_MLP()\n",
    "if torch.cuda.is_available():\n",
    "    mlp.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde449e-0a66-44e3-9169-3cc23657349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's train our network!\n",
    "train_network_classification(mlp, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b4fe46-7f29-424d-908c-e33b7b1ed37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data and split it into train and test sets\n",
    "data, target = fetch_california_housing(return_X_y=True)\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.3)\n",
    "\n",
    "# Since we are using PyTorch, we need tensors!\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "test_x = torch.tensor(test_x, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "test_y = torch.tensor(test_y, dtype=torch.float32)\n",
    "\n",
    "# Then we convert those tensors to a TensorDataset\n",
    "train_california = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "test_california = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "\n",
    "# And create our DataLoaders!\n",
    "train_loader = DataLoader(train_california, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_california, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b3ac10-071b-4a94-bf6c-000e932e23fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Housing_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = F.relu\n",
    "        self.hidden = nn.Linear(8, 2)\n",
    "        self.prediction = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden(x))\n",
    "        x = self.prediction(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Do not change the name of your model or later cells may fail!\n",
    "mlp = Housing_MLP()\n",
    "if torch.cuda.is_available():\n",
    "    mlp.cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
